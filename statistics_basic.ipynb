{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics Basics"
      ],
      "metadata": {
        "id": "TByyWr3W2muO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** What is statistics, and why is it important?\n",
        "**ans-** Statistics is the branch of mathematics that deals with collecting, analyzing, interpreting, and presenting data. It helps identify patterns, trends, and relationships in data. Statistics is crucial for making informed decisions in various fields, like business, healthcare, and social sciences. It enables prediction and risk assessment, guiding actions based on evidence. In essence, statistics turns raw data into meaningful insights."
      ],
      "metadata": {
        "id": "vdIeV41q25m1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.**  What are the two main types of statistics?\n",
        "**ans-** The two main types of statistics are descriptive statistics and inferential statistics.\n",
        "\n",
        "Descriptive statistics involves summarizing and organizing data, using measures like mean, median, mode, and standard deviation. It describes the basic features of the data.\n",
        "Inferential statistics focuses on making predictions or inferences about a population based on a sample of data. It involves techniques like hypothesis testing, confidence intervals, and regression analysis."
      ],
      "metadata": {
        "id": "y6RPGAWJ3aJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** What are descriptive statistics?\n",
        "**ans-** Descriptive statistics involves summarizing and organizing data to identify patterns or trends. It includes measures like mean, median, mode, range, and standard deviation. These statistics provide a simple overview of the data's central tendency and variability. The goal is to present data in a clear, understandable way."
      ],
      "metadata": {
        "id": "x7O0EJcb2pIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.** What is inferential statistics?\n",
        "**ans-** Inferential statistics involves making predictions or generalizations about a population based on a sample of data. It uses techniques like hypothesis testing, confidence intervals, and regression analysis. This type of statistics helps draw conclusions that extend beyond the immediate data. It enables decision-making based on limited information."
      ],
      "metadata": {
        "id": "jkiaCb1j5HAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.**  What is sampling in statistics?\n",
        "**ans-** Sampling in statistics is the process of selecting a subset of individuals or items from a larger population. It allows researchers to draw conclusions about the entire population without examining every member. Different sampling methods include random, stratified, and systematic sampling. Proper sampling ensures that the sample is representative of the population. The goal is to make reliable inferences with minimal cost and time."
      ],
      "metadata": {
        "id": "k_OQQII55WSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.** What are the different types of sampling methods?\n",
        "**ans-** Random Sampling: Every member of the population has an equal chance of being selected. It reduces bias and provides a representative sample.\n",
        "\n",
        "Stratified Sampling: The population is divided into subgroups (strata) based on a specific characteristic, and samples are randomly chosen from each stratum.\n",
        "\n",
        "Systematic Sampling: A starting point is chosen randomly, and then every nth member of the population is selected.\n",
        "\n",
        "Cluster Sampling: The population is divided into clusters, and entire clusters are randomly selected for the sample.\n",
        "\n",
        "Convenience Sampling: Samples are selected based on ease of access, though this may lead to biases and is often less representative."
      ],
      "metadata": {
        "id": "IyCNxdcL52r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.** What is the difference between random and non-random sampling?\n",
        "**ans-** Random Sampling: Every member of the population has an equal chance of being selected. This method aims to eliminate bias and produce a representative sample. Examples include simple random sampling, stratified sampling, and systematic sampling.\n",
        "\n",
        "Non-Random Sampling: The selection of samples is not based on chance, and some individuals may have a higher likelihood of being chosen than others. This method is more subjective and can introduce bias. Examples include convenience sampling, judgmental sampling, and quota sampling."
      ],
      "metadata": {
        "id": "c_gZE8BZ6Ssb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.** Define and give examples of qualitative and quantitative data.\n",
        "ans- Qualitative Data (also called categorical data) refers to non-numeric information that describes qualities or characteristics. It often involves categories or labels.\n",
        "\n",
        "Examples:\n",
        "Colors of cars (red, blue, green)\n",
        "Types of fruit (apple, banana, cherry)\n",
        "Gender (male, female)\n",
        "Marital status (single, married, divorced)\n",
        "Quantitative Data refers to numeric data that can be measured and counted. It represents quantities and is often used for mathematical calculations.\n",
        "\n",
        "Examples:\n",
        "Height (in centimeters or inches)\n",
        "Age (in years)\n",
        "Temperature (in degrees Celsius or Fahrenheit)\n",
        "Number of students in a class"
      ],
      "metadata": {
        "id": "D0F0eJJn6l5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.** What are the different types of data in statistics?\n",
        "**ans-** Nominal Data: Categorical data that represents names or labels with no intrinsic order. Examples include gender, eye color, and nationality.\n",
        "\n",
        "Ordinal Data: Categorical data with a meaningful order or ranking, but the intervals between ranks are not uniform. Examples include educational level (high school, bachelor’s, master’s) or class rankings (first, second, third).\n",
        "\n",
        "Interval Data: Numeric data with equal intervals between values, but no true zero point. Examples include temperature in Celsius or Fahrenheit, where zero doesn’t mean \"no temperature.\"\n",
        "\n",
        "Ratio Data: Numeric data with equal intervals and a true zero point, allowing for meaningful ratios. Examples include height, weight, age, and income.\n",
        "\n",
        "Discrete Data: Quantitative data that can only take specific, distinct values, often counted. Examples include the number of children in a family or the number of cars in a parking lot.\n",
        "\n",
        "Continuous Data: Quantitative data that can take any value within a given range and is measurable. Examples include height, weight, or time."
      ],
      "metadata": {
        "id": "t4CPbJwpBZDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.** Explain nominal, ordinal, interval, and ratio levels of measurement.\n",
        "**ans-** Nominal: Categorical data without any order or ranking. Examples: gender, color, nationality. It's just about naming or labeling.\n",
        "\n",
        "Ordinal: Data with a meaningful order or ranking, but the differences between the ranks are not necessarily equal. Examples: rankings (1st, 2nd, 3rd), satisfaction levels (poor, good, excellent).\n",
        "\n",
        "Interval: Numeric data with meaningful intervals between values, but no true zero point. Examples: temperature in Celsius or Fahrenheit (0°C or 0°F doesn't mean \"no temperature\").\n",
        "\n",
        "Ratio: Numeric data with equal intervals and a true zero point, meaning you can make meaningful ratios. Examples: height, weight, age, income (zero means none)."
      ],
      "metadata": {
        "id": "7OIWfjT3BrEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11.**  What is the measure of central tendency?\n",
        "**ans-** The measure of central tendency is a statistical concept that describes the center or typical value of a dataset. It represents the \"middle\" of the data and helps summarize a set of values with a single representative number. There are three main measures of central tendency:\n",
        "\n",
        "Mean: The arithmetic average of all the values in a dataset. It’s calculated by summing all the values and dividing by the number of values. (Best used for normally distributed data.)\n",
        "\n",
        "Median: The middle value when the data is arranged in ascending or descending order. If there’s an even number of values, the median is the average of the two middle values. (Useful when the data has outliers.)\n",
        "\n",
        "Mode: The value that occurs most frequently in a dataset. A dataset may have one mode, more than one (bimodal, multimodal), or none at all if all values occur with the same frequency."
      ],
      "metadata": {
        "id": "iianlwdKCGik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.** Define mean, median, and mode.\n",
        "**ans-** Mean: The arithmetic average of all the values in a dataset. It’s calculated by summing all the values and dividing by the number of values. (Best used for normally distributed data.)\n",
        "\n",
        "Median: The middle value when the data is arranged in ascending or descending order. If there’s an even number of values, the median is the average of the two middle values. (Useful when the data has outliers.)\n",
        "\n",
        "Mode: The value that occurs most frequently in a dataset. A dataset may have one mode, more than one (bimodal, multimodal), or none at all if all values occur with the same frequency."
      ],
      "metadata": {
        "id": "LTHyiemtCssB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13.**  What is the significance of the measure of central tendency?\n",
        "**ans-** The measure of central tendency is significant because it provides a single value that summarizes a dataset, helping to understand the \"center\" or typical value of the data. Here’s why it’s important:\n",
        "\n",
        "Simplification: It condenses a large set of data into a single number, making it easier to interpret and communicate. Instead of describing each value in the dataset, you can focus on this central value.\n",
        "\n",
        "Comparison: It allows for easy comparison between different datasets. For example, you can compare the average income of people in different regions or the median test scores of students in different schools.\n",
        "\n",
        "Insights: By identifying the typical value, measures of central tendency help identify patterns, trends, and anomalies in the data. It can also show where most data points are clustered.\n",
        "\n",
        "Decision-Making: It helps in making decisions based on the central trend. For instance, in business, understanding the average sales figures can guide production, pricing, and marketing strategies.\n",
        "\n",
        "Handling Variability: Measures like the median are helpful in situations where data may have outliers or skewed distributions (like income or housing prices), as they provide a better representation of the \"typical\" value in such cases."
      ],
      "metadata": {
        "id": "NnDM6qVRC4po"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14.** What is variance, and how is it calculated?\n",
        "**ans-** Variance is a statistical measure that indicates the degree of spread or dispersion of a set of data points around the mean (average). It tells you how much the individual values in a dataset differ from the mean. A higher variance means the data points are more spread out; a lower variance indicates that the data points are closer to the mean.\n",
        "                  \n",
        "                  "
      ],
      "metadata": {
        "id": "h5vaQa_YDKBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15.** What is standard deviation, and why is it important?\n",
        "**ans-** Standard deviation is a measure of the amount of variation or dispersion in a set of values. It tells you how much individual data points differ from the mean of the dataset. A low standard deviation means the data points are close to the mean, while a high standard deviation means the data points are spread out over a wider range of values.\n",
        "Why is Standard Deviation Important?\n",
        "Understanding Spread: It gives a clearer idea of how spread out the data is around the mean. For example, in finance, a high standard deviation of stock prices indicates a higher level of risk or volatility.\n",
        "\n",
        "Comparison Across Datasets: It helps compare the variability of different datasets. If you have two datasets with the same mean, the one with the higher standard deviation has more variability.\n",
        "\n",
        "Data Interpretation: It helps to understand how much the values differ from the average. A smaller standard deviation means most values are close to the mean, whereas a larger one shows more variability.\n",
        "\n",
        "Informed Decision-Making: In business, manufacturing, and research, standard deviation is used to assess consistency or predict future outcomes. For instance, knowing the standard deviation of production times can help a factory determine how reliably they meet deadlines.\n",
        "\n",
        "Foundation for Other Stats: Standard deviation is the basis for many other statistical analyses, like z-scores, confidence intervals, and hypothesis testing."
      ],
      "metadata": {
        "id": "68s3iE7oJjqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16.**  Define and explain the term range in statistics.\n",
        "**ans-** In statistics, range refers to the difference between the highest and lowest values in a dataset. It is a simple measure of the spread or dispersion of data, showing how far apart the extreme values (maximum and minimum) are from each other.\n",
        "\n",
        "Formula: Range = Maximum Value−Minimum Value"
      ],
      "metadata": {
        "id": "Si0Gv3KYKyfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.** What is the difference between variance and standard deviation?\n",
        "**ans-** Variance measures the average squared deviation of data points from the mean and is in squared units. Standard deviation is the square root of variance and is in the same units as the original data, making it easier to interpret. Both measure the spread of data, but standard deviation is more commonly used for practical interpretation. Variance is useful in statistical calculations, while standard deviation provides a clearer sense of variability. Variance can be harder to interpret due to its squared units, while standard deviation is more intuitive.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ti8mHQrhLz0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18.** What is skewness in a dataset?\n",
        "**ans-** Skewness refers to the measure of the asymmetry or lack of symmetry in a dataset's distribution. It indicates whether the data is evenly distributed around the mean or if it is biased towards one side.\n",
        "\n",
        "Positive Skew (Right Skew): The right tail (larger values) is longer or fatter, meaning the majority of data points are on the left side of the mean.\n",
        "Negative Skew (Left Skew): The left tail (smaller values) is longer or fatter, meaning most data points are on the right side of the mean.\n",
        "Zero Skew: The data is symmetrically distributed around the mean, like in a normal distribution."
      ],
      "metadata": {
        "id": "i_5P7IZFMPg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19.** What does it mean if a dataset is positively or negatively skewed?\n",
        "**ans-** If a dataset is positively skewed (right-skewed), it means that the right tail (larger values) of the distribution is longer or fatter than the left tail. This suggests that the majority of the data points are concentrated on the left side of the mean, with a few larger values pulling the mean to the right. In this case, the mean is greater than the median. Common examples include income distributions and housing prices, where a few high values skew the data.\n",
        "\n",
        "If a dataset is negatively skewed (left-skewed), it means that the left tail (smaller values) is longer or fatter than the right tail. This indicates that the majority of the data points are concentrated on the right side of the mean, with a few smaller values pulling the mean to the left. In this case, the mean is less than the median. Examples might include ages at retirement or test scores where most values are high, but a few low scores skew the data."
      ],
      "metadata": {
        "id": "OpebRJr1MiwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20.** Define and explain kurtosis.\n",
        "**ans-** Kurtosis is a statistical measure that describes the shape of the distribution of data, particularly the \"tailedness\" or the sharpness of the peak. It tells you how much data points are in the tails (extreme values) compared to the center of the distribution. In other words, kurtosis helps identify whether a dataset has outliers or extreme values."
      ],
      "metadata": {
        "id": "SeiQT5IINE1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21.** What is the purpose of covariance?\n",
        "**ans-** Purpose of Covariance:\n",
        "Measure of Relationship: Covariance helps to determine whether two variables have a positive, negative, or no relationship:\n",
        "\n",
        "Positive Covariance: Both variables tend to increase or decrease together.\n",
        "Negative Covariance: When one variable increases, the other decreases, and vice versa.\n",
        "Zero Covariance: No predictable relationship between the variables.\n",
        "Direction of Relationship: While correlation (a related measure) provides a standardized measure of the relationship strength, covariance shows the direction of the relationship (whether the variables move together or in opposite directions).\n",
        "\n",
        "Risk Assessment: In finance, covariance is used to measure how the returns of two assets move together. This is important for portfolio diversification, as assets with negative covariance can reduce overall portfolio risk.\n",
        "\n"
      ],
      "metadata": {
        "id": "TzGLg4xvNTr_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22.** What does correlation measure in statistics?\n",
        "**ans-** Correlation measures the strength and direction of the linear relationship between two variables. It ranges from -1 to +1:\n",
        "\n",
        "+1: Perfect positive correlation.\n",
        "-1: Perfect negative correlation.\n",
        "0: No linear correlation.\n",
        "Positive correlation means both variables move in the same direction, while negative correlation means they move in opposite directions. Correlation helps predict one variable based on the other and is widely used in data analysis to identify relationships between variables.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XPUGSVFjNv_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23.** What is the difference between covariance and correlation?\n",
        "**ans-** The main differences between covariance and correlation are:\n",
        "\n",
        "Scale:\n",
        "\n",
        "Covariance depends on the units of the variables, making it difficult to compare across different datasets.\n",
        "Correlation is a standardized measure, with values ranging from -1 to +1, making it unit-independent and easier to compare across datasets.\n",
        "Interpretability:\n",
        "\n",
        "Covariance indicates the direction of the relationship (positive or negative) but not the strength in a standardized way.\n",
        "Correlation provides both the direction and strength of the relationship, allowing for clearer interpretation.\n",
        "Range:\n",
        "\n",
        "Covariance can take any value, depending on the scale of the variables.\n",
        "Correlation is always between -1 (perfect negative) and +1 (perfect positive), with 0 meaning no linear relationship.\n",
        "Usage:\n",
        "\n",
        "Covariance is often used in portfolio theory and variance calculations.\n",
        "Correlation is used more widely in data analysis for comparing the strength and direction of relationships between variables."
      ],
      "metadata": {
        "id": "laibfjjsOI15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24.** What are some real-world applications of statistics?\n",
        "**ans-** Statistics is widely used in various fields to make informed decisions, analyze data, and predict outcomes. Some real-world applications include:\n",
        "\n",
        "Healthcare: In clinical trials, statistics help determine the effectiveness of treatments, analyze patient data, and track disease outbreaks.\n",
        "Finance: Investors use statistics to analyze market trends, assess risk, and make investment decisions through models like portfolio optimization.\n",
        "Marketing: Companies use statistics for customer behavior analysis, targeted advertising, and sales forecasting, often using data from surveys and purchase patterns.\n",
        "Sports: Analysts use statistics to evaluate player performance, team strategies, and predict outcomes in games (e.g., player batting averages or win probabilities).\n",
        "Education: Statistics are used to assess student performance, design surveys, and evaluate the effectiveness of educational programs.\n",
        "Government: Governments use statistics for policy making, population census, crime rate analysis, and economic planning."
      ],
      "metadata": {
        "id": "CKpJegcEOX3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical"
      ],
      "metadata": {
        "id": "Y_XSkU9MOrZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** How do you calculate the mean, median, and mode of a dataset?\n",
        "**ans-**To calculate the mean, median, and mode of a dataset:\n",
        "\n",
        "Mean: Add all the values and divide by the total number of values.\n",
        "\n",
        "Median: Arrange the data in ascending order, and:\n",
        "\n",
        "If the number of values is odd, the middle value is the median.\n",
        "If even, the median is the average of the two middle values.\n",
        "\n",
        "Mode: Identify the value that occurs most frequently. If multiple values appear the same number of times, the dataset is multi-modal; if no value repeats, there is no mode."
      ],
      "metadata": {
        "id": "iOcxmKBTcKAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Write a Python program to compute the variance and standard deviation of a dataset."
      ],
      "metadata": {
        "id": "rnrM0QxAcxew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "data = [4, 7, 8, 10, 15]\n",
        "\n",
        "variance = statistics.variance(data)\n",
        "print(f\"Variance: {variance}\")\n",
        "\n",
        "std_deviation = statistics.stdev(data)\n",
        "print(f\"Standard Deviation: {std_deviation}\")\n"
      ],
      "metadata": {
        "id": "iUcFekzPd82A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** Create a dataset and classify it into nominal, ordinal, interval, and ratio types."
      ],
      "metadata": {
        "id": "T1VEoMM3eEZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataset\n",
        "dataset = {\n",
        "    'Student_ID': [101, 102, 103, 104],\n",
        "    'Grade': ['A', 'B', 'A', 'C'],\n",
        "    'Temperature_C': [20, 25, 30, 35],\n",
        "    'Height_cm': [150, 160, 170, 180]\n",
        "}\n",
        "\n",
        "# Function to display the data type classifications\n",
        "def classify_data(dataset):\n",
        "    print(\"Dataset Classification:\")\n",
        "    for key, value in dataset.items():\n",
        "        if key == 'Student_ID':\n",
        "            print(f\"{key}: Nominal (Just labels, no order)\")\n",
        "        elif key == 'Grade':\n",
        "            print(f\"{key}: Ordinal (Ordered categories with meaningful order)\")\n",
        "        elif key == 'Temperature_C':\n",
        "            print(f\"{key}: Interval (Meaningful difference, no absolute zero)\")\n",
        "        elif key == 'Height_cm':\n",
        "            print(f\"{key}: Ratio (Has absolute zero and meaningful differences)\")\n",
        "\n",
        "# Calling the function to classify the dataset\n",
        "classify_data(dataset)\n"
      ],
      "metadata": {
        "id": "ABz3bgEXfAMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.**  Implement sampling techniques like random sampling and stratified sampling.\n"
      ],
      "metadata": {
        "id": "VeCTVix8fWBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "data = {\n",
        "    'ID': range(1, 101),\n",
        "    'Age': np.random.randint(18, 60, 100),\n",
        "    'Income': np.random.randint(20000, 100000, 100),\n",
        "    'Category': np.random.choice(['A', 'B', 'C'], 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "### **1. Random Sampling (यादृच्छिक सैंपलिंग)**\n",
        "random_sample = df.sample(n=10, random_state=42)\n",
        "print(\"Random Sampling:\\n\", random_sample)\n",
        "\n",
        "### **2. Stratified Sampling (स्तरीकृत सैंपलिंग)**\n",
        "# Stratify by 'Category'\n",
        "stratified_sample, _ = train_test_split(df, test_size=0.9, stratify=df['Category'], random_state=42)\n",
        "\n",
        "print(\"\\nStratified Sampling:\\n\", stratified_sample)\n"
      ],
      "metadata": {
        "id": "5CdFflNPfhhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.** Write a Python function to calculate the range of a dataset."
      ],
      "metadata": {
        "id": "JfE3rU9fiey5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_range(dataset):\n",
        "    # Find the maximum and minimum values in the dataset\n",
        "    max_value = max(dataset)\n",
        "    min_value = min(dataset)\n",
        "\n",
        "    # Calculate the range\n",
        "    range_value = max_value - min_value\n",
        "    return range_value\n",
        "\n",
        "# Sample dataset\n",
        "data = [4, 7, 8, 10, 15]\n",
        "\n",
        "# Calculate the range\n",
        "range_of_data = calculate_range(data)\n",
        "print(f\"The range of the dataset is: {range_of_data}\")\n"
      ],
      "metadata": {
        "id": "sbwBvz7Ejcvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.** Create a dataset and plot its histogram to visualize skewness."
      ],
      "metadata": {
        "id": "VzhEFC8_lOnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(data, kde=True, color=\"skyblue\", bins=30)\n",
        "\n",
        "# Adding title and labels\n",
        "plt.title(\"Histogram to Visualize Skewness (Right Skewed)\", fontsize=15)\n",
        "plt.xlabel(\"Value\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vOY_YPUOla5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.** Calculate skewness and kurtosis of a dataset using Python libraries."
      ],
      "metadata": {
        "id": "_-rf47jEluRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Calculate Skewness\n",
        "skewness = stats.skew(data)\n",
        "print(f\"Skewness: {skewness}\")\n",
        "\n",
        "kurtosis = stats.kurtosis(data)\n",
        "print(f\"Kurtosis: {kurtosis}\")\n"
      ],
      "metadata": {
        "id": "2Q3ewCwkl0RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.** Generate a dataset and demonstrate positive and negative skewness.\n"
      ],
      "metadata": {
        "id": "mKmdPuZemEa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Positive skew (Right-skewed) using exponential distribution\n",
        "positive_skew_data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Negative skew (Left-skewed) using log-normal distribution\n",
        "negative_skew_data = np.random.lognormal(mean=0, sigma=1, size=1000)\n",
        "\n",
        "# Plot both distributions\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Positive skew plot\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(positive_skew_data, kde=True, color=\"skyblue\", bins=30)\n",
        "plt.title(\"Positive Skew\")\n",
        "\n",
        "# Negative skew plot\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(negative_skew_data, kde=True, color=\"salmon\", bins=30)\n",
        "plt.title(\"Negative Skew\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vephsjwRmrIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.** Write a Python script to calculate covariance between two datasets."
      ],
      "metadata": {
        "id": "-2O5aqaRm8CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data1 = [5, 8, 12, 14, 18]\n",
        "data2 = [7, 11, 15, 16, 20]\n",
        "\n",
        "covariance_matrix = np.cov(data1, data2)\n",
        "\n",
        "covariance = covariance_matrix[0, 1]\n",
        "\n",
        "print(f\"Covariance between the two datasets: {covariance}\")\n"
      ],
      "metadata": {
        "id": "mMHDA5SRnCXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.** Write a Python script to calculate the correlation coefficient between two datasets."
      ],
      "metadata": {
        "id": "nzozrzPxnN41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "dataset_1 = [10, 20, 30, 40, 50]\n",
        "dataset_2 = [15, 25, 35, 45, 55]\n",
        "\n",
        "correlation_matrix = np.corrcoef(dataset_1, dataset_2)\n",
        "\n",
        "correlation_coefficient = correlation_matrix[0, 1]\n",
        "\n",
        "print(\"Correlation Coefficient:\", correlation_coefficient)\n"
      ],
      "metadata": {
        "id": "fYCPC6dZnX3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11.**  Create a scatter plot to visualize the relationship between two variables."
      ],
      "metadata": {
        "id": "1k50-6VOnrga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset_1 = [10, 20, 30, 40, 50]\n",
        "dataset_2 = [15, 25, 35, 45, 55]\n",
        "\n",
        "plt.scatter(dataset_1, dataset_2, color='blue', marker='o')\n",
        "\n",
        "plt.xlabel('Dataset 1')\n",
        "plt.ylabel('Dataset 2')\n",
        "plt.title('Scatter Plot: Dataset 1 vs Dataset 2')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SXOWJMaqnxie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.**  Implement and compare simple random sampling and systematic sampling."
      ],
      "metadata": {
        "id": "GWVJN0kMn9O-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13.**  Calculate the mean, median, and mode of grouped data."
      ],
      "metadata": {
        "id": "-wdGrZa2oM4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14.** Simulate data using Python and calculate its central tendency and dispersion."
      ],
      "metadata": {
        "id": "CUq4U3AcoiVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "data = np.random.normal(50, 10, 1000)\n",
        "\n",
        "# Central Tendency\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "mode = stats.mode(data)[0][0]\n",
        "\n",
        "# Dispersion\n",
        "variance = np.var(data)\n",
        "std_dev = np.std(data)\n",
        "\n",
        "# Print results\n",
        "print(f\"Mean: {mean:.2f}, Median: {median:.2f}, Mode: {mode:.2f}\")\n",
        "print(f\"Variance: {variance:.2f}, Standard Deviation: {std_dev:.2f}\")\n"
      ],
      "metadata": {
        "id": "RdjQshGDo3DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15.**  Use NumPy or pandas to summarize a dataset’s descriptive statistics."
      ],
      "metadata": {
        "id": "aGYVZyOfo7YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Simulate some data\n",
        "data = np.random.normal(50, 10, 1000)  # 1000 points with mean=50 and std=10\n",
        "\n",
        "# Convert data into a pandas DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"Value\"])\n",
        "\n",
        "# Descriptive statistics summary using pandas\n",
        "summary = df.describe()\n",
        "\n",
        "# Display the summary\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "DnzOqh98pMDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16.**  Plot a boxplot to understand the spread and identify outliers."
      ],
      "metadata": {
        "id": "zRJmnV33pNf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = np.random.normal(50, 10, 1000)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=data, color='skyblue', width=0.5)\n",
        "\n",
        "plt.title('Boxplot of Simulated Data')\n",
        "plt.xlabel('Data')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k4YD_Ed1pZZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.**  Calculate the interquartile range (IQR) of a dataset."
      ],
      "metadata": {
        "id": "cNSNxDN_pfOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.normal(50, 10, 1000)  # 1000 points with mean=50 and std=10\n",
        "\n",
        "# Calculate Q1 and Q3\n",
        "Q1 = np.percentile(data, 25)\n",
        "Q3 = np.percentile(data, 75)\n",
        "\n",
        "# Calculate IQR\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "print(f\"First Quartile (Q1): {Q1:.2f}\")\n",
        "print(f\"Third Quartile (Q3): {Q3:.2f}\")\n",
        "print(f\"Interquartile Range (IQR): {IQR:.2f}\")\n"
      ],
      "metadata": {
        "id": "fr97rj8Zpz4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18.** Implement Z-score normalization and explain its significance."
      ],
      "metadata": {
        "id": "FQ3KsDKJp-sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.normal(50, 10, 1000)  # Mean=50, Std=10, Number of points=1000\n",
        "\n",
        "mean = np.mean(data)\n",
        "std_dev = np.std(data)\n",
        "\n",
        "z_scores = (data - mean) / std_dev\n",
        "\n",
        "# Print first 10 Z-scores as an example\n",
        "print(\"First 10 Z-scores:\", z_scores[:10])\n"
      ],
      "metadata": {
        "id": "5oqvJShtqHAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19.**  Compare two datasets using their standard deviations."
      ],
      "metadata": {
        "id": "TdlfvqXcqYA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate two datasets\n",
        "data1 = np.random.normal(50, 10, 1000)\n",
        "data2 = np.random.normal(50, 20, 1000)\n",
        "\n",
        "std_dev_1 = np.std(data1)\n",
        "std_dev_2 = np.std(data2)\n",
        "\n",
        "\n",
        "print(f\"Standard Deviation of Dataset 1: {std_dev_1:.2f}\")\n",
        "print(f\"Standard Deviation of Dataset 2: {std_dev_2:.2f}\")\n",
        "\n",
        "# Interpret the results\n",
        "if std_dev_1 > std_dev_2:\n",
        "    print(\"Dataset 1 has a higher spread (greater variability) than Dataset 2.\")\n",
        "else:\n",
        "    print(\"Dataset 2 has a higher spread (greater variability) than Dataset 1.\")\n"
      ],
      "metadata": {
        "id": "IMdPZXUOqetL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20.**  Write a Python program to visualize covariance using a heatmap."
      ],
      "metadata": {
        "id": "y3UcrAIqqsmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21.** Use seaborn to create a correlation matrix for a dataset."
      ],
      "metadata": {
        "id": "CVME4Oa_q-14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(50, 10, 1000)  # Dataset 1\n",
        "data2 = 0.5 * data1 + np.random.normal(0, 5, 1000)\n",
        "data3 = np.random.normal(30, 5, 1000)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Dataset 1': data1,\n",
        "    'Dataset 2': data2,\n",
        "    'Dataset 3': data3\n",
        "})\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True, vmin=-1, vmax=1)\n",
        "\n",
        "# Add title\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GtF8HBc0rF5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22.** Generate a dataset and implement both variance and standard deviation computations."
      ],
      "metadata": {
        "id": "kY5BV5KarX0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.normal(50, 10, 1000)\n",
        "\n",
        "mean = np.mean(data)\n",
        "\n",
        "variance = np.mean((data - mean) ** 2)\n",
        "\n",
        "std_deviation = np.sqrt(variance)\n",
        "\n",
        "variance_np = np.var(data)\n",
        "std_deviation_np = np.std(data)\n",
        "\n",
        "# Print results\n",
        "print(f\"Mean of the data: {mean:.2f}\")\n",
        "print(f\"Manually computed Variance: {variance:.2f}\")\n",
        "print(f\"Manually computed Standard Deviation: {std_deviation:.2f}\")\n",
        "print(f\"Variance using NumPy: {variance_np:.2f}\")\n",
        "print(f\"Standard Deviation using NumPy: {std_deviation_np:.2f}\")\n"
      ],
      "metadata": {
        "id": "jp3iUYAHrcrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23.**  Visualize skewness and kurtosis using Python libraries like matplotlib or seaborn."
      ],
      "metadata": {
        "id": "NKX-tiVbrsGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24.** Implement the Pearson and Spearman correlation coefficients for a dataset."
      ],
      "metadata": {
        "id": "ExC6RcBxr999"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kn57pFkRsGiN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}